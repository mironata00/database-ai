services:
  postgres_master:
    image: postgres:17-alpine
    container_name: db_ai_v2_postgres_master
    environment:
      POSTGRES_DB: ${POSTGRES_DB}
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_INITDB_ARGS: "-E UTF8 --locale=ru_RU.UTF-8"
    volumes:
      - postgres_master_data:/var/lib/postgresql/data
      - ./back/init_extensions.sql:/docker-entrypoint-initdb.d/init_extensions.sql
    ports:
      - "${POSTGRES_PORT:-5432}:5432"
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER}"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - db_ai_v2_network
    restart: unless-stopped

  postgres_replica:
    image: postgres:17-alpine
    container_name: db_ai_v2_postgres_replica
    environment:
      POSTGRES_DB: ${POSTGRES_DB}
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      PGUSER: ${POSTGRES_USER}
    command: |
      bash -c "
      until pg_basebackup --pgdata=/var/lib/postgresql/data -R --slot=replication_slot --host=postgres_master --port=5432 --username=${POSTGRES_USER}; do
        echo 'Waiting for master to be ready...'
        sleep 2
      done
      postgres
      "
    volumes:
      - postgres_replica_data:/var/lib/postgresql/data
    depends_on:
      postgres_master:
        condition: service_healthy
    networks:
      - db_ai_v2_network
    restart: unless-stopped
    profiles:
      - replica

  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.11.0
    container_name: db_ai_v2_elasticsearch
    environment:
      - discovery.type=single-node
      - xpack.security.enabled=${ES_SECURITY_ENABLED}
      - xpack.security.http.ssl.enabled=false
      - "ES_JAVA_OPTS=-Xms${ES_HEAP_SIZE} -Xmx${ES_HEAP_SIZE}"
      - cluster.name=${ES_CLUSTER_NAME}
      - bootstrap.memory_lock=true
    ulimits:
      memlock:
        soft: -1
        hard: -1
      nofile:
        soft: 65536
        hard: 65536
    volumes:
      - elasticsearch_data:/usr/share/elasticsearch/data
      - ./back/elasticsearch/mappings:/usr/share/elasticsearch/config/mappings
    ports:
      - "${ES_PORT:-9200}:9200"
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:9200/_cluster/health || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 5
    networks:
      - db_ai_v2_network
    restart: unless-stopped

  redis_master:
    image: redis:7-alpine
    container_name: db_ai_v2_redis_master
    command: redis-server --requirepass ${REDIS_PASSWORD} --maxmemory ${REDIS_MAX_MEMORY} --maxmemory-policy allkeys-lru
    volumes:
      - redis_master_data:/data
    ports:
      - "${REDIS_PORT:-6379}:6379"
    healthcheck:
      test: ["CMD", "redis-cli", "--raw", "incr", "ping"]
      interval: 10s
      timeout: 3s
      retries: 5
    networks:
      - db_ai_v2_network
    restart: unless-stopped

  redis_sentinel:
    image: redis:7-alpine
    container_name: db_ai_v2_redis_sentinel
    command: redis-sentinel /etc/redis/sentinel.conf
    volumes:
      - ./back/redis/sentinel.conf:/etc/redis/sentinel.conf
    depends_on:
      - redis_master
    networks:
      - db_ai_v2_network
    restart: unless-stopped
    profiles:
      - ha

  minio:
    image: minio/minio:latest
    container_name: db_ai_v2_minio
    command: server /data --console-address ":9001"
    environment:
      MINIO_ROOT_USER: ${MINIO_ROOT_USER}
      MINIO_ROOT_PASSWORD: ${MINIO_ROOT_PASSWORD}
    volumes:
      - minio_data:/data
    ports:
      - "${MINIO_PORT:-9000}:9000"
      - "${MINIO_CONSOLE_PORT:-9001}:9001"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9000/minio/health/live"]
      interval: 30s
      timeout: 20s
      retries: 3
    networks:
      - db_ai_v2_network
    restart: unless-stopped

  api:
    build:
      context: ./back
      dockerfile: Dockerfile
    container_name: db_ai_v2_api
    env_file:
      - .env
    volumes:
      - ./uploads:/app/uploads
      - ./back:/app
      - api_logs:/app/logs
    ports:
      - "${API_PORT:-8000}:8000"
    depends_on:
      postgres_master:
        condition: service_healthy
      elasticsearch:
        condition: service_healthy
      redis_master:
        condition: service_healthy
      minio:
        condition: service_healthy
    command: uvicorn app.main:app --host 0.0.0.0 --port 8000 --reload
    networks:
      - db_ai_v2_network
    restart: unless-stopped

  celery_worker_email:
    build:
      context: ./back
      dockerfile: Dockerfile
    container_name: db_ai_v2_celery_email
    env_file:
      - .env
    volumes:
      - ./back:/app
      - celery_logs:/app/logs
    depends_on:
      - postgres_master
      - redis_master
      - minio
    command: celery -A app.tasks.celery_app worker -Q email_queue -n email_worker@%h --loglevel=${CELERY_LOG_LEVEL} --concurrency=${CELERY_EMAIL_CONCURRENCY}
    networks:
      - db_ai_v2_network
    restart: unless-stopped

  celery_worker_parsing:
    build:
      context: ./back
      dockerfile: Dockerfile
    container_name: db_ai_v2_celery_parsing
    env_file:
      - .env
    volumes:
      - ./back:/app
      - celery_logs:/app/logs
    depends_on:
      - postgres_master
      - elasticsearch
      - redis_master
      - minio
    command: celery -A app.tasks.celery_app worker -Q parsing_queue -n parsing_worker@%h --loglevel=${CELERY_LOG_LEVEL} --concurrency=${CELERY_PARSING_CONCURRENCY}
    networks:
      - db_ai_v2_network
    restart: unless-stopped

  celery_worker_search:
    build:
      context: ./back
      dockerfile: Dockerfile
    container_name: db_ai_v2_celery_search
    env_file:
      - .env
    volumes:
      - ./back:/app
      - celery_logs:/app/logs
    depends_on:
      - elasticsearch
      - redis_master
    command: celery -A app.tasks.celery_app worker -Q search_queue -n search_worker@%h --loglevel=${CELERY_LOG_LEVEL} --concurrency=${CELERY_SEARCH_CONCURRENCY}
    networks:
      - db_ai_v2_network
    restart: unless-stopped

  celery_beat:
    build:
      context: ./back
      dockerfile: Dockerfile
    container_name: db_ai_v2_celery_beat
    env_file:
      - .env
    volumes:
      - ./back:/app
      - celery_logs:/app/logs
    depends_on:
      - redis_master
    command: celery -A app.tasks.celery_app beat --loglevel=${CELERY_LOG_LEVEL}
    networks:
      - db_ai_v2_network
    restart: unless-stopped

  flower:
    build:
      context: ./back
      dockerfile: Dockerfile
    container_name: db_ai_v2_flower
    env_file:
      - .env
    ports:
      - "${FLOWER_PORT:-5555}:5555"
    depends_on:
      - redis_master
    command: celery -A app.tasks.celery_app flower --port=5555
    networks:
      - db_ai_v2_network
    restart: unless-stopped
    profiles:
      - monitoring

  nginx:
    image: nginx:alpine
    container_name: db_ai_v2_nginx
    volumes:
      - ./nginx/html:/usr/share/nginx/html
      - ./nginx/nginx.conf:/etc/nginx/nginx.conf
      - ./nginx/ssl:/etc/nginx/ssl
    ports:
      - "${NGINX_HTTP_PORT:-80}:80"
      - "${NGINX_HTTPS_PORT:-443}:443"
    depends_on:
      - api
      - frontend
    networks:
      - db_ai_v2_network
    restart: unless-stopped

  frontend:
    build:
      context: ./front
      dockerfile: Dockerfile
    container_name: db_ai_v2_frontend
    env_file:
      - .env
    volumes:
      - ./front:/app
      - /app/node_modules
    ports:
      - "${FRONTEND_PORT:-3000}:3000"
    networks:
      - db_ai_v2_network
    restart: unless-stopped

volumes:
  postgres_master_data:
  postgres_replica_data:
  elasticsearch_data:
  redis_master_data:
  minio_data:
  api_logs:
  celery_logs:

networks:
  db_ai_v2_network:
    driver: bridge
